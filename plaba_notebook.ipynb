{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Talida-M/BIO_NLP_PLABA_2023/blob/main/plaba_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "skB7DPLgAkB2",
      "metadata": {
        "id": "skB7DPLgAkB2"
      },
      "source": [
        "\n",
        "# Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tZSRQtjHAijM",
      "metadata": {
        "id": "tZSRQtjHAijM"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps xformers \"trl<0.9.0\" peft accelerate bitsandbytes\n",
        "!pip install rouge_score\n",
        "!pip install evaluation\n",
        "!pip install datasets\n",
        "!pip install numpy\n",
        "!pip install torch\n",
        "!pip install nltk\n",
        "!pip install sacrebleu sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7pMPLo3wiECb",
      "metadata": {
        "id": "7pMPLo3wiECb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import unicodedata\n",
        "import math\n",
        "import argparse\n",
        "import random\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from unsloth import FastLanguageModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aENxajwgTkK6",
      "metadata": {
        "id": "aENxajwgTkK6"
      },
      "source": [
        "# Loading base Mistral model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_Jj7TxkHTjCE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Jj7TxkHTjCE",
        "outputId": "b5e581df-55a0-4bf1-c41b-cf00d274b605"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth: Fast Mistral patching release 2024.6\n",
            "   \\\\   /|    GPU: NVIDIA L4. Max memory: 22.168 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = TRUE. Xformers = 0.0.26.post1. FA = False.\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: Will load unsloth/mistral-7b-v0.3-bnb-4bit as a legacy tokenizer.\n"
          ]
        }
      ],
      "source": [
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "base_model, base_tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/mistral-7b-v0.3\", # Choose ANY! eg teknium/OpenHermes-2.5-Mistral-7B\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")\n",
        "\n",
        "FastLanguageModel.for_inference(base_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading and preprocessing"
      ],
      "metadata": {
        "id": "SJBebNZUCz5U"
      },
      "id": "SJBebNZUCz5U"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K4mkYnek5ATO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4mkYnek5ATO",
        "outputId": "796714d7-502e-40e0-ae78-f2fb7dd58197"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load Data from Google Drive or locally\n",
        "COLAB_ENABLED=True # Loads from Google Drive if True\n",
        "\n",
        "if COLAB_ENABLED:\n",
        "    # DATA_PATH = \"/content/drive/MyDrive/biomedical_nlp/data\"\n",
        "    DATA_PATH = \"/content/drive/MyDrive/BIO_NLP/\"\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    #%% md\n",
        "else:\n",
        "    DATA_PATH = \"./data\"\n",
        "\n",
        "# Load the dataset\n",
        "with open(DATA_PATH + '/data.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(json.dumps(data, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CBSNlJAdWaXa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "collapsed": true,
        "id": "CBSNlJAdWaXa",
        "outputId": "24dc694c-ffde-4e5f-fb44-88bc29a79a6e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 9085,\n  \"fields\": [\n    {\n      \"column\": \"question_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21,\n        \"min\": 1,\n        \"max\": 75,\n        \"num_unique_values\": 75,\n        \"samples\": [\n          5,\n          64,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 75,\n        \"samples\": [\n          \"How to treat a bakers cyst?\",\n          \"How is scn1a gene disorder tested?\",\n          \"How to treat phda1?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"B\",\n          \"C\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 75,\n        \"samples\": [\n          \"How to treat a bakers cyst?\",\n          \"How is scn1a gene disorder tested?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"adaptations\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9064,\n        \"samples\": [\n          \"Treatment with Quinomycin A reduced kidney weight to body weight ratio and reduced kidney cystic area and scarred tissue in mice with PKD.\",\n          \"The most recent and relevant treatments on the biology and treatment of these conditions have been included.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstracts\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7451,\n        \"samples\": [\n          \"Knockout mouse models suggest that OSR1 mainly activates NKCC2, while SPAK mainly activates NCC, with possible cross-compensation.\",\n          \"We report five cases of pattern alopecia in female patients who are undergoing hormonal anticancer therapy for the prevention of recurrence of breast cancer after surgery.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a9cdb738-48a2-4c5a-95c6-e06c5d4284d6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_id</th>\n",
              "      <th>question</th>\n",
              "      <th>question_type</th>\n",
              "      <th>title</th>\n",
              "      <th>adaptations</th>\n",
              "      <th>abstracts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>What causes muscle spasm?</td>\n",
              "      <td>C</td>\n",
              "      <td>What causes muscle spasm?</td>\n",
              "      <td>Muscle cramps are a common problem represented...</td>\n",
              "      <td>Muscle cramps are a common problem characteriz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>What causes muscle spasm?</td>\n",
              "      <td>C</td>\n",
              "      <td>What causes muscle spasm?</td>\n",
              "      <td>These true cramps, coming from nerves outside ...</td>\n",
              "      <td>These true cramps, which originate from periph...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>What causes muscle spasm?</td>\n",
              "      <td>C</td>\n",
              "      <td>What causes muscle spasm?</td>\n",
              "      <td>Medical history, physical check-up, and lab sc...</td>\n",
              "      <td>Medical history, physical examination, and a l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>What causes muscle spasm?</td>\n",
              "      <td>C</td>\n",
              "      <td>What causes muscle spasm?</td>\n",
              "      <td>Despite their harmless nature, cramps are unco...</td>\n",
              "      <td>Despite the \"benign\" nature of cramps, many pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>What causes muscle spasm?</td>\n",
              "      <td>C</td>\n",
              "      <td>What causes muscle spasm?</td>\n",
              "      <td>Experience and limited medical studies guide t...</td>\n",
              "      <td>Treatment options are guided both by experienc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9cdb738-48a2-4c5a-95c6-e06c5d4284d6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a9cdb738-48a2-4c5a-95c6-e06c5d4284d6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a9cdb738-48a2-4c5a-95c6-e06c5d4284d6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a48e7b27-751e-4a28-b339-2fab56efc447\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a48e7b27-751e-4a28-b339-2fab56efc447')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a48e7b27-751e-4a28-b339-2fab56efc447 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   question_id                   question question_type  \\\n",
              "0            1  What causes muscle spasm?             C   \n",
              "1            1  What causes muscle spasm?             C   \n",
              "2            1  What causes muscle spasm?             C   \n",
              "3            1  What causes muscle spasm?             C   \n",
              "4            1  What causes muscle spasm?             C   \n",
              "\n",
              "                       title  \\\n",
              "0  What causes muscle spasm?   \n",
              "1  What causes muscle spasm?   \n",
              "2  What causes muscle spasm?   \n",
              "3  What causes muscle spasm?   \n",
              "4  What causes muscle spasm?   \n",
              "\n",
              "                                         adaptations  \\\n",
              "0  Muscle cramps are a common problem represented...   \n",
              "1  These true cramps, coming from nerves outside ...   \n",
              "2  Medical history, physical check-up, and lab sc...   \n",
              "3  Despite their harmless nature, cramps are unco...   \n",
              "4  Experience and limited medical studies guide t...   \n",
              "\n",
              "                                           abstracts  \n",
              "0  Muscle cramps are a common problem characteriz...  \n",
              "1  These true cramps, which originate from periph...  \n",
              "2  Medical history, physical examination, and a l...  \n",
              "3  Despite the \"benign\" nature of cramps, many pa...  \n",
              "4  Treatment options are guided both by experienc...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if not os.path.exists(DATA_PATH + '/test_dataset.csv'):\n",
        "  dfs = []\n",
        "  question_data = {\"question_id\": [], \"question\": [], \"question_type\": [], \"title\": \"\", \"adaptations\": [], \"abstracts\": []}\n",
        "  for key, value in data.items():\n",
        "      abstracts = []\n",
        "      adaptations = []\n",
        "      for sub_key, sub_value in value.items():\n",
        "          if isinstance(sub_value, dict):\n",
        "              for adaptation in sub_value['adaptations']:\n",
        "                  for adaptation_key, adaptation_value in sub_value['adaptations'][adaptation].items():\n",
        "                      adaptations.append(adaptation_value)\n",
        "                      abstracts.append(sub_value['abstract'][adaptation_key])\n",
        "\n",
        "          question_data[\"abstracts\"] = abstracts\n",
        "          question_data[\"adaptations\"] = adaptations\n",
        "          question_data[\"question_id\"] = [key] * len(adaptations)\n",
        "          question_data[\"question_type\"] = [value[\"question_type\"]] * len(adaptations)\n",
        "          question_data[\"question\"] = [value[\"question\"]] * len(adaptations)\n",
        "          question_data[\"title\"] = [value[\"question\"]] * len(adaptations)\n",
        "          assert len(adaptations) == len(abstracts), f\"len {len(adaptations)} not equal {len(abstracts)}\"\n",
        "      dfs.append(pd.DataFrame.from_dict(question_data))\n",
        "  df = pd.concat(dfs)\n",
        "  df.to_csv(DATA_PATH + 'test_dataset.csv', index=False)\n",
        "else:\n",
        "  df = pd.read_csv(DATA_PATH + 'test_dataset.csv', header=0)\n",
        "\n",
        "# Keep rows where at least one value is not missing in both columns (using ~ for negation and all() for checking all True)\n",
        "df = df[~(df[\"abstracts\"].isnull() | df[\"adaptations\"].isnull())]\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "STBAk3_5stQO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STBAk3_5stQO",
        "outputId": "6003de47-03de-4909-94f2-ea8f62d8a383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries in test set: 1373\n",
            "Number of entries in val set: 1458\n",
            "Number of entries in train set: 6488\n"
          ]
        }
      ],
      "source": [
        "# Split up dataset into train/val/test -> 70/15/15\n",
        "if not os.path.exists(DATA_PATH + 'train.csv'):\n",
        "  # Clean the question column\n",
        "  df['question_id'] = df['question_id'].astype(str)\n",
        "\n",
        "  # Define test size (15%) and validation size (15%)\n",
        "  test_size = 0.15\n",
        "  val_size = 0.15\n",
        "  train_size = 1 - test_size - val_size\n",
        "\n",
        "  train_val, test = train_test_split(df, test_size=test_size, random_state=42)\n",
        "  train, val = train_test_split(train_val, test_size=val_size/(val_size+train_size), random_state=42)\n",
        "\n",
        "  dfs = {'train': train, 'val': val, 'test': test}\n",
        "\n",
        "  for key, df in dfs.items():\n",
        "      df.to_csv(DATA_PATH + key + \".csv\", index=False, encoding='utf-8-sig')\n",
        "else:\n",
        "    train = pd.read_csv(DATA_PATH + 'train.csv', header=0)\n",
        "    val = pd.read_csv(DATA_PATH + 'val.csv', header=0)\n",
        "    test = pd.read_csv(DATA_PATH + 'test.csv', header=0)\n",
        "    dfs = {'train':train, 'val':val, 'test':test}\n",
        "\n",
        "print(\"Number of entries in test set:\", len(test))\n",
        "print(\"Number of entries in val set:\", len(val))\n",
        "print(\"Number of entries in train set:\", len(train))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PDxSvotIAqcQ",
      "metadata": {
        "id": "PDxSvotIAqcQ"
      },
      "source": [
        "# Mistral Finetuning using unsloth (RUN ONLY IF YOU WANT TO FINETUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bVqi1gLQgIRQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "03b3c227a8184ab58a52b199bb15c028",
            "12d20264d4bd45f4981bbea4c202ff35",
            "673988099abd481f91db8b6020cd64a1",
            "8e1df5cf65ce40fcbb39beada7248251",
            "0b24ce17caa44d15be30e285cbbb3f92",
            "327d63dbbbf541f682afa947e7dc2e43",
            "728fd2c8fc6c40d7bf6bf6690ba96193",
            "df00e22b03d8451b848ce60d441306c7",
            "fa54912fe07a46adab0857a06d11ca2c",
            "4962b4e213c84c1a93bb5fa3785b67b6",
            "f2402ecc3e7e473687a38d3dba5ea1e5"
          ]
        },
        "id": "bVqi1gLQgIRQ",
        "outputId": "83df2994-ff44-410c-962c-1d16399db653"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03b3c227a8184ab58a52b199bb15c028",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7946 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## Prompt generation\n",
        "prompt = \"\"\"\n",
        "### Instruction:\n",
        "You are a medical advisor that takes in a very abstract sentence and translates it in layman's terms, for average people to understand.\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = base_tokenizer.eos_token # Must add EOS_TOKEN\n",
        "\n",
        "def formatting_prompts_func(data):\n",
        "    texts = []\n",
        "    for input, output in zip(data[\"abstracts\"], data[\"adaptations\"]):\n",
        "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
        "        text = prompt.format(input, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "\n",
        "from datasets import Dataset, concatenate_datasets\n",
        "\n",
        "dataset = concatenate_datasets([Dataset.from_pandas(train), Dataset.from_pandas(val)])\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MoGtnfP29TkE",
      "metadata": {
        "id": "MoGtnfP29TkE"
      },
      "outputs": [],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    base_model,\n",
        "    r = 16,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YUSPKyIwAxng",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "18d46064da714d88b8f7396663361d53",
            "35d64dc78a0d4f0ca1c79cf575fd638b",
            "6eb2b3a5d29a435ea160f36bed770051",
            "571960902212497f9e3fdaa518c86c0b",
            "d94c93647835475ba934aec7f6fdd377",
            "c53604ce15ae469ab1ff7b0627cb8720",
            "d56c400f637343849429f568ec30d747",
            "c76a10b5e3134d9ab4aa30b1b96af1a4",
            "4182c1481d6f4953a9713f554eb16a12",
            "60cc92dd70204ade80ea385bc0a41a66",
            "dc71bb27486446f39e92a2746a9dc97d"
          ]
        },
        "id": "YUSPKyIwAxng",
        "outputId": "da1e47e0-862a-45f1-eb64-a64914609d8c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18d46064da714d88b8f7396663361d53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/7946 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = base_tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        num_train_epochs = 1,\n",
        "        # max_steps = 60, # Set num_train_epochs = 1 for full training runs\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0-JSNWJT9ptP",
      "metadata": {
        "collapsed": true,
        "id": "0-JSNWJT9ptP"
      },
      "outputs": [],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4RCsyKzvYo5l",
      "metadata": {
        "id": "4RCsyKzvYo5l"
      },
      "source": [
        "### Saving the model locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UtuFPacSAmwy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtuFPacSAmwy",
        "outputId": "b141d2bc-32ad-44b7-e33c-30029ddc6e6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/BIO_NLP/lora/lora_model_5_full/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/BIO_NLP/lora/lora_model_5_full/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/BIO_NLP/lora/lora_model_5_full/tokenizer.model',\n",
              " '/content/drive/MyDrive/BIO_NLP/lora/lora_model_5_full/added_tokens.json')"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(DATA_PATH + \"lora/lora_model\") # Local saving\n",
        "tokenizer.save_pretrained(DATA_PATH + \"lora/lora_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vvxb7yr3Yh9B",
      "metadata": {
        "id": "vvxb7yr3Yh9B"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NXZg7nXKmWrn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXZg7nXKmWrn",
        "outputId": "a7c5097e-d1ef-488b-eccb-74b97b4d57bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth: Fast Mistral patching release 2024.6\n",
            "   \\\\   /|    GPU: NVIDIA L4. Max memory: 22.168 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = TRUE. Xformers = 0.0.26.post1. FA = False.\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: Will load unsloth/mistral-7b-v0.3-bnb-4bit as a legacy tokenizer.\n"
          ]
        }
      ],
      "source": [
        "# Loading the model, change to True when loading. Be sure to have the lora_model folder in DATA_PATH\n",
        "if True:\n",
        "    from unsloth import FastLanguageModel\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = DATA_PATH + \"/lora/lora_model_5_full\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length = max_seq_length,\n",
        "        dtype = dtype,\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xIW9JEhz_F2Z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xIW9JEhz_F2Z",
        "outputId": "667150ee-5671-4030-c5d2-2d43f789d248"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Desogestrel and cyproterone acetate had the highest risk estimates.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Desogestrel and cyproterone acetate had the highest risk estimates.'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def mistral_inference(model, tokenizer, input):\n",
        "    ### Instruction:\n",
        "    inference_prompt = \"\"\"\n",
        "    ### Instruction:\n",
        "    You are a medical advisor that takes in an abstract sentence and translates it in layman's terms, for average people to understand.\n",
        "\n",
        "    ### Input:\n",
        "    {}\n",
        "\n",
        "    ### Response:\n",
        "    {}\n",
        "    \"\"\"\n",
        "\n",
        "    FastLanguageModel.for_inference(model)\n",
        "    inputs = tokenizer([inference_prompt.format(input)], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "    outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    decoded_output = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "\n",
        "    #Extract the response part\n",
        "    response_start = decoded_output.find(\"### Response:\") + len(\"### Response:\")\n",
        "    response = decoded_output[response_start:].strip()\n",
        "\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BfAZfwMvnKze",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "BfAZfwMvnKze",
        "outputId": "5988c48a-d94e-426f-fa8a-91564b7b0d93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Desogestrel and cyproterone acetate had the highest risk estimates.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Desogestrel and cyproterone acetate had the highest risk estimates.'"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mistral_inference(base_model, base_tokenizer, \"Desogestrel and cyproterone acetate had the highest risk estimates: 14·6 (9·7-21·9) and 32·6 (13·2-80·6) and 15·5 (9·7-24·9) and 44·4 (16·9-116·3) respectively.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NFdWN9WIRILw",
      "metadata": {
        "id": "NFdWN9WIRILw"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "finetune_responses = []\n",
        "base_model_finetune_responses = []\n",
        "for abstract in tqdm(dfs['test']['abstracts']):\n",
        "    base_model_finetune_responses.append(mistral_inference(base_model, base_tokenizer, abstract))\n",
        "\n",
        "for abstract in tqdm(dfs['test']['abstracts']):\n",
        "    finetune_responses.append(mistral_inference(model, base_tokenizer, abstract)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M4AOyn7zlTCf",
      "metadata": {
        "id": "M4AOyn7zlTCf"
      },
      "outputs": [],
      "source": [
        "dfs['test']['base_model_finetune_responses'] = base_model_finetune_responses\n",
        "dfs['test']['finetune_responses'] = finetune_responses\n",
        "\n",
        "dfs['test'].to_csv(DATA_PATH + \"test.csv\", index=False, encoding='utf-8-sig')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab901164",
      "metadata": {
        "id": "ab901164"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de74da8c",
      "metadata": {
        "id": "de74da8c",
        "outputId": "4684f946-116f-41d5-eb73-17793cc4d7c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1373\n"
          ]
        }
      ],
      "source": [
        "# read in test if not existing\n",
        "try:\n",
        "    test = dfs.test\n",
        "except:\n",
        "    test = pd.read_csv(\"test.csv\")\n",
        "#test = test.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c1813c",
      "metadata": {
        "id": "e5c1813c",
        "outputId": "b1d7528d-65ec-43a8-80a4-92b8d38e919e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1345/1345 [05:20<00:00,  4.20it/s]\n",
            "100%|██████████| 1345/1345 [06:30<00:00,  3.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average SARI Base: 45.95831370112784,       Max SARI Base: 94.74634298163708,       Min SARI Base: 3.03030303030303\n",
            "Average SARI Finetuned: 50.50778739221534,       Max SARI Finetuned: 100.0,       Min SARI Finetuned: 9.37626331923324\n",
            "Average BLEU Base: 0.18285801561409298,       Max BLEU Base: 0.9635749534339606,       Min BLEU Base: 0.0\n",
            "Average BLEU Finetuned: 0.2809257388079612,       Max BLEU Finetuned: 1.0,       Min BLEU Finetuned: 0.0\n",
            "Average ROUGE Base: 0.416878485870897,       Max ROUGE Base: 1.0,       Min ROUGE Base: 0.0\n",
            "Average ROUGE Finetuned: 0.5490284189462421,       Max ROUGE Finetuned: 1.0,       Min ROUGE Finetuned: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from evaluate import load\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the SARI evaluation metric\n",
        "sari = load(\"sari\")\n",
        "\n",
        "# Load the BLEU evaluation metric\n",
        "bleu = load(\"bleu\")\n",
        "\n",
        "# Load the ROUGE evaluation metric\n",
        "rouge = load('rouge')\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "test['sari_base'] = test.progress_apply(lambda row: sari.compute(sources=[row['abstracts']],\n",
        "                                      references=[[row['adaptations']]],\n",
        "                                      predictions=[row['base_model_finetune_responses']])['sari'], axis=1)\n",
        "\n",
        "test['sari_finetuned'] = test.progress_apply(lambda row: sari.compute(sources=[row['abstracts']],\n",
        "                                      references=[[row['adaptations']]],\n",
        "                                      predictions=[row['finetuned_mistral_responses']])['sari'], axis=1)\n",
        "\n",
        "test['bleu_base'] = test.progress_apply(lambda row: bleu.compute(\n",
        "                                      references=[[row['adaptations']]],\n",
        "                                      predictions=[row['base_model_finetune_responses']])['bleu'], axis=1)\n",
        "\n",
        "test['bleu_finetuned'] = test.progress_apply(lambda row: bleu.compute(\n",
        "                                      references=[[row['adaptations']]],\n",
        "                                      predictions=[row['finetuned_mistral_responses']])['bleu'], axis=1)\n",
        "\n",
        "test['rouge_base'] = test.progress_apply(lambda row: rouge.compute(\n",
        "                                      references=[[row['adaptations']]],\n",
        "                                      predictions=[row['base_model_finetune_responses']])['rougeL'], axis=1)\n",
        "\n",
        "test['rouge_finetuned'] = test.progress_apply(lambda row: rouge.compute(\n",
        "                                      references=[[row['adaptations']]],\n",
        "                                      predictions=[row['finetuned_mistral_responses']])['rougeL'], axis=1)\n",
        "\n",
        "print(f'Average SARI Base: {sum(test.sari_base)/len(test.sari_base)}, \\\n",
        "      Max SARI Base: {max(test.sari_base)}, \\\n",
        "      Min SARI Base: {min(test.sari_base)}')\n",
        "\n",
        "print(f'Average SARI Finetuned: {sum(test.sari_finetuned)/len(test.sari_finetuned)}, \\\n",
        "      Max SARI Finetuned: {max(test.sari_finetuned)}, \\\n",
        "      Min SARI Finetuned: {min(test.sari_finetuned)}')\n",
        "\n",
        "print(f'Average BLEU Base: {sum(test.bleu_base)/len(test.bleu_base)}, \\\n",
        "      Max BLEU Base: {max(test.bleu_base)}, \\\n",
        "      Min BLEU Base: {min(test.bleu_base)}')\n",
        "\n",
        "print(f'Average BLEU Finetuned: {sum(test.bleu_finetuned)/len(test.bleu_finetuned)}, \\\n",
        "      Max BLEU Finetuned: {max(test.bleu_finetuned)}, \\\n",
        "      Min BLEU Finetuned: {min(test.bleu_finetuned)}')\n",
        "\n",
        "print(f'Average ROUGE Base: {sum(test.rouge_base)/len(test.rouge_base)}, \\\n",
        "      Max ROUGE Base: {max(test.rouge_base)}, \\\n",
        "      Min ROUGE Base: {min(test.rouge_base)}')\n",
        "\n",
        "print(f'Average ROUGE Finetuned: {sum(test.rouge_finetuned)/len(test.rouge_finetuned)}, \\\n",
        "      Max ROUGE Finetuned: {max(test.rouge_finetuned)}, \\\n",
        "      Min ROUGE Finetuned: {min(test.rouge_finetuned)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34e64bec",
      "metadata": {
        "id": "34e64bec",
        "outputId": "e10b51dc-d4af-4ab6-af10-92435919649c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'She decided to leave the hospital on her own, but she will have to come back for a follow-up visit.  The input sentence is a medical term that means the patient decided to leave the hospital on their own, but they'"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test.to_csv(\"eval.csv\", index=False, encoding='utf-8-sig')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03b3c227a8184ab58a52b199bb15c028": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12d20264d4bd45f4981bbea4c202ff35",
              "IPY_MODEL_673988099abd481f91db8b6020cd64a1",
              "IPY_MODEL_8e1df5cf65ce40fcbb39beada7248251"
            ],
            "layout": "IPY_MODEL_0b24ce17caa44d15be30e285cbbb3f92"
          }
        },
        "0b24ce17caa44d15be30e285cbbb3f92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12d20264d4bd45f4981bbea4c202ff35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_327d63dbbbf541f682afa947e7dc2e43",
            "placeholder": "​",
            "style": "IPY_MODEL_728fd2c8fc6c40d7bf6bf6690ba96193",
            "value": "Map: 100%"
          }
        },
        "18d46064da714d88b8f7396663361d53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35d64dc78a0d4f0ca1c79cf575fd638b",
              "IPY_MODEL_6eb2b3a5d29a435ea160f36bed770051",
              "IPY_MODEL_571960902212497f9e3fdaa518c86c0b"
            ],
            "layout": "IPY_MODEL_d94c93647835475ba934aec7f6fdd377"
          }
        },
        "327d63dbbbf541f682afa947e7dc2e43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35d64dc78a0d4f0ca1c79cf575fd638b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c53604ce15ae469ab1ff7b0627cb8720",
            "placeholder": "​",
            "style": "IPY_MODEL_d56c400f637343849429f568ec30d747",
            "value": "Map (num_proc=2): 100%"
          }
        },
        "4182c1481d6f4953a9713f554eb16a12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4962b4e213c84c1a93bb5fa3785b67b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "571960902212497f9e3fdaa518c86c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60cc92dd70204ade80ea385bc0a41a66",
            "placeholder": "​",
            "style": "IPY_MODEL_dc71bb27486446f39e92a2746a9dc97d",
            "value": " 7946/7946 [00:04&lt;00:00, 1645.30 examples/s]"
          }
        },
        "60cc92dd70204ade80ea385bc0a41a66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "673988099abd481f91db8b6020cd64a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df00e22b03d8451b848ce60d441306c7",
            "max": 7946,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa54912fe07a46adab0857a06d11ca2c",
            "value": 7946
          }
        },
        "6eb2b3a5d29a435ea160f36bed770051": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c76a10b5e3134d9ab4aa30b1b96af1a4",
            "max": 7946,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4182c1481d6f4953a9713f554eb16a12",
            "value": 7946
          }
        },
        "728fd2c8fc6c40d7bf6bf6690ba96193": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e1df5cf65ce40fcbb39beada7248251": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4962b4e213c84c1a93bb5fa3785b67b6",
            "placeholder": "​",
            "style": "IPY_MODEL_f2402ecc3e7e473687a38d3dba5ea1e5",
            "value": " 7946/7946 [00:00&lt;00:00, 129487.73 examples/s]"
          }
        },
        "c53604ce15ae469ab1ff7b0627cb8720": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c76a10b5e3134d9ab4aa30b1b96af1a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d56c400f637343849429f568ec30d747": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d94c93647835475ba934aec7f6fdd377": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc71bb27486446f39e92a2746a9dc97d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df00e22b03d8451b848ce60d441306c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2402ecc3e7e473687a38d3dba5ea1e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa54912fe07a46adab0857a06d11ca2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}